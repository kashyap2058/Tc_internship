{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890     0.0  \n",
       "1                  0.1860          0.2750                  0.08902     0.0  \n",
       "2                  0.2430          0.3613                  0.08758     0.0  \n",
       "3                  0.2575          0.6638                  0.17300     0.0  \n",
       "4                  0.1625          0.2364                  0.07678     0.0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115     0.0  \n",
       "565                0.1628          0.2572                  0.06637     0.0  \n",
       "566                0.1418          0.2218                  0.07820     0.0  \n",
       "567                0.2650          0.4087                  0.12400     0.0  \n",
       "568                0.0000          0.2871                  0.07039     1.0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Breast Cancer dataset\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "df = pd.DataFrame(np.c_[data['data'], data['target']],\n",
    "                  columns= np.append(data['feature_names'], ['target']))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the describe method and explain the results\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "target                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NULL item in the dataframe\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of the target (Outcome) and show the count and show the distribution ratio\n",
    "sns.countplot(df,x='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 indicates no cancer and 0 indicates cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    357\n",
       "0.0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For column  mean radius  the range is  21.128999999999998\n",
      "For column  mean texture  the range is  29.57\n",
      "For column  mean perimeter  the range is  144.71\n",
      "For column  mean area  the range is  2357.5\n",
      "For column  mean smoothness  the range is  0.11076999999999998\n",
      "For column  mean compactness  the range is  0.32602\n",
      "For column  mean concavity  the range is  0.4268\n",
      "For column  mean concave points  the range is  0.2012\n",
      "For column  mean symmetry  the range is  0.198\n",
      "For column  mean fractal dimension  the range is  0.04748\n",
      "For column  radius error  the range is  2.7615000000000003\n",
      "For column  texture error  the range is  4.5248\n",
      "For column  perimeter error  the range is  21.223\n",
      "For column  area error  the range is  535.398\n",
      "For column  smoothness error  the range is  0.029417000000000002\n",
      "For column  compactness error  the range is  0.133148\n",
      "For column  concavity error  the range is  0.396\n",
      "For column  concave points error  the range is  0.05279\n",
      "For column  symmetry error  the range is  0.071068\n",
      "For column  fractal dimension error  the range is  0.028945199999999997\n",
      "For column  worst radius  the range is  28.11\n",
      "For column  worst texture  the range is  37.519999999999996\n",
      "For column  worst perimeter  the range is  200.79\n",
      "For column  worst area  the range is  4068.8\n",
      "For column  worst smoothness  the range is  0.15143\n",
      "For column  worst compactness  the range is  1.03071\n",
      "For column  worst concavity  the range is  1.252\n",
      "For column  worst concave points  the range is  0.291\n",
      "For column  worst symmetry  the range is  0.5073\n",
      "For column  worst fractal dimension  the range is  0.15245999999999998\n",
      "For column  target  the range is  1.0\n"
     ]
    }
   ],
   "source": [
    "# Check the range of data from the above describe method on each feature column\n",
    "for column in df.columns:\n",
    "    a=0\n",
    "    b=0\n",
    "    a=df[column].min()\n",
    "    b=df[column].max()\n",
    "    print(\"For column \",column,\" the range is \",b-a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the scaling using StandardScaler on the columns\n",
    "x=df.drop(['target'],axis=1)\n",
    "y=df['target']\n",
    "scl=StandardScaler()\n",
    "x_data=scl.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_data,y,random_state=RANDOM_STATE,stratify=y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((171, 30), (398, 30))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape,x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for the XGBoost classifier\n",
    "xgb=XGBClassifier(n_estimators=100,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "xgb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred=xgb.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245    1.0\n",
       "450    1.0\n",
       "48     1.0\n",
       "36     0.0\n",
       "564    0.0\n",
       "      ... \n",
       "327    1.0\n",
       "413    1.0\n",
       "499    0.0\n",
       "42     0.0\n",
       "380    1.0\n",
       "Name: target, Length: 171, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "conf=confusion_matrix(y_test,y_pred)\n",
    "clf_rep=classification_report(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:\n",
      "0.9707602339181286\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96        64\n",
      "         1.0       0.99      0.96      0.98       107\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.97      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 63   1]\n",
      " [  4 103]]\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation results\n",
    "print(\"Test set accuracy:\")\n",
    "print(acc)\n",
    "print(\"\\nClassification report:\")\n",
    "print(clf_rep)\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
